{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baseline Model Training and Evaluation\n",
        "\n",
        "This notebook trains and evaluates baseline machine learning models:\n",
        "- Logistic Regression (L1 regularization)\n",
        "- Random Forest\n",
        "- XGBoost\n",
        "- MLP (Deep Learning)\n",
        "- 1D-CNN (Deep Learning)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, confusion_matrix,\n",
        "    classification_report, roc_curve\n",
        ")\n",
        "\n",
        "from preprocessing import MetabolomicsPreprocessor\n",
        "from features import FeatureSelector\n",
        "from models.baseline import BaselineModels\n",
        "from models.deep import MLP, CNN1D, DeepModelTrainer, MetabolomicsDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and preprocess data\n",
        "data_path = Path('../data/synthetic/synthetic_urine_metabolomics.csv')\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Prepare labels (binary: control vs cancer)\n",
        "y = (df['diagnosis_label'] != 'control').astype(int).values\n",
        "print(f\"Class distribution: {np.bincount(y)}\")\n",
        "\n",
        "# Preprocessing\n",
        "preprocessor = MetabolomicsPreprocessor(\n",
        "    imputation_method='knn',\n",
        "    normalization_method='log2',\n",
        "    batch_correction=True,\n",
        "    scale_method='zscore'\n",
        ")\n",
        "\n",
        "X = preprocessor.fit_transform(df)\n",
        "print(f\"Preprocessed X shape: {X.shape}\")\n",
        "\n",
        "# Feature selection\n",
        "feature_selector = FeatureSelector(\n",
        "    method='univariate',\n",
        "    n_features=min(200, X.shape[1]),\n",
        "    variance_threshold=0.01\n",
        ")\n",
        "\n",
        "X_selected = feature_selector.fit_transform(X, y)\n",
        "print(f\"Selected features: {X_selected.shape[1]}\")\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_selected, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\nTrain set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train baseline models\n",
        "baseline = BaselineModels()\n",
        "results = {}\n",
        "\n",
        "print(\"Training models...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Logistic Regression\n",
        "print(\"\\n1. Logistic Regression (L1)\")\n",
        "baseline.train_logistic_regression(X_train, y_train, penalty='l1', C=0.1)\n",
        "y_pred_lr = baseline.predict('logistic', X_test)\n",
        "y_proba_lr = baseline.predict_proba('logistic', X_test)\n",
        "results['logistic'] = {\n",
        "    'accuracy': accuracy_score(y_test, y_pred_lr),\n",
        "    'f1': f1_score(y_test, y_pred_lr, average='weighted', zero_division=0),\n",
        "    'roc_auc': roc_auc_score(y_test, y_proba_lr[:, 1])\n",
        "}\n",
        "print(f\"Accuracy: {results['logistic']['accuracy']:.4f}\")\n",
        "\n",
        "# Random Forest\n",
        "print(\"\\n2. Random Forest\")\n",
        "baseline.train_random_forest(X_train, y_train, n_estimators=100, max_depth=10)\n",
        "y_pred_rf = baseline.predict('random_forest', X_test)\n",
        "y_proba_rf = baseline.predict_proba('random_forest', X_test)\n",
        "results['random_forest'] = {\n",
        "    'accuracy': accuracy_score(y_test, y_pred_rf),\n",
        "    'f1': f1_score(y_test, y_pred_rf, average='weighted', zero_division=0),\n",
        "    'roc_auc': roc_auc_score(y_test, y_proba_rf[:, 1])\n",
        "}\n",
        "print(f\"Accuracy: {results['random_forest']['accuracy']:.4f}\")\n",
        "\n",
        "# XGBoost\n",
        "print(\"\\n3. XGBoost\")\n",
        "baseline.train_xgboost(X_train, y_train, n_estimators=100, max_depth=6)\n",
        "y_pred_xgb = baseline.predict('xgboost', X_test)\n",
        "y_proba_xgb = baseline.predict_proba('xgboost', X_test)\n",
        "results['xgboost'] = {\n",
        "    'accuracy': accuracy_score(y_test, y_pred_xgb),\n",
        "    'f1': f1_score(y_test, y_pred_xgb, average='weighted', zero_division=0),\n",
        "    'roc_auc': roc_auc_score(y_test, y_proba_xgb[:, 1])\n",
        "}\n",
        "print(f\"Accuracy: {results['xgboost']['accuracy']:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
