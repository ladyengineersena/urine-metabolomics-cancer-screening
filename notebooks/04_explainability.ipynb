{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Explainability with SHAP\n",
        "\n",
        "This notebook demonstrates model interpretability using SHAP (SHapley Additive exPlanations) values.\n",
        "\n",
        "SHAP helps understand which metabolites are most important for model predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "\n",
        "import shap\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# Initialize SHAP (suppress warnings)\n",
        "shap.initjs()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data and preprocess (same as training)\n",
        "data_path = Path('../data/synthetic/synthetic_urine_metabolomics.csv')\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "y = (df['diagnosis_label'] != 'control').astype(int).values\n",
        "\n",
        "from preprocessing import MetabolomicsPreprocessor\n",
        "from features import FeatureSelector\n",
        "from models.baseline import BaselineModels\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "preprocessor = MetabolomicsPreprocessor(\n",
        "    imputation_method='knn',\n",
        "    normalization_method='log2',\n",
        "    batch_correction=True,\n",
        "    scale_method='zscore'\n",
        ")\n",
        "\n",
        "X = preprocessor.fit_transform(df)\n",
        "\n",
        "feature_selector = FeatureSelector(\n",
        "    method='univariate',\n",
        "    n_features=min(200, X.shape[1]),\n",
        "    variance_threshold=0.01\n",
        ")\n",
        "\n",
        "X_selected = feature_selector.fit_transform(X, y)\n",
        "\n",
        "# Get feature names\n",
        "metab_cols = [col for col in df.columns if col.startswith('metab_')]\n",
        "if hasattr(feature_selector, 'selected_features'):\n",
        "    selected_metab_cols = [metab_cols[i] for i in range(len(metab_cols)) \n",
        "                         if feature_selector.selected_features[i]]\n",
        "else:\n",
        "    selected_metab_cols = [f\"feature_{i}\" for i in range(X_selected.shape[1])]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_selected, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train.shape}\")\n",
        "print(f\"Test set: {X_test.shape}\")\n",
        "print(f\"Selected features: {len(selected_metab_cols)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train a model for explanation (Random Forest)\n",
        "baseline = BaselineModels()\n",
        "baseline.train_random_forest(X_train, y_train, n_estimators=100, max_depth=10)\n",
        "\n",
        "model = baseline.models['random_forest']\n",
        "print(\"Model trained for explanation\")\n",
        "\n",
        "# Create SHAP explainer\n",
        "print(\"Creating SHAP explainer...\")\n",
        "explainer = shap.TreeExplainer(model)\n",
        "\n",
        "# Calculate SHAP values (use subset for speed)\n",
        "n_samples = min(100, len(X_test))\n",
        "sample_indices = np.random.choice(len(X_test), n_samples, replace=False)\n",
        "X_explain = X_test[sample_indices]\n",
        "\n",
        "print(f\"Calculating SHAP values for {n_samples} samples...\")\n",
        "shap_values = explainer.shap_values(X_explain)\n",
        "\n",
        "# For binary classification, use positive class\n",
        "if isinstance(shap_values, list):\n",
        "    shap_values = shap_values[1]\n",
        "\n",
        "print(f\"SHAP values shape: {shap_values.shape}\")\n",
        "\n",
        "# Get top features\n",
        "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
        "top_indices = np.argsort(mean_abs_shap)[-20:][::-1]\n",
        "\n",
        "top_features = pd.DataFrame({\n",
        "    'feature': [selected_metab_cols[i] for i in top_indices],\n",
        "    'mean_abs_shap': mean_abs_shap[top_indices]\n",
        "})\n",
        "\n",
        "print(\"\\nTop 20 Most Important Features:\")\n",
        "print(top_features)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
